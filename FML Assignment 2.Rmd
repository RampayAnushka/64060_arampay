---
title: "FML Assignment-2"
author: "Anushka Rampay"
date: "2024-02-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Summary

1)If the new customer does not take out a personal loan, it would be marked as zero.

2)K=3 is just right because it doesn't overfit and doesn't ignore information from the predictors.

3)Below is the confusion matrix for the validation data that was made with the best K and parameters like TP=142, TN=1786, FP=63, and FN=9, and an accuracy of 0.964.

4)When the best K is used, the customer is labeled as 0 and doesn't take out a personal loan.

5)When the training, validation, and test sets don't perform the same, it could mean that there are problems like overfitting or inconsistent data. Keep an eye out for these changes and make any necessary changes to the model to make sure it works well with the new data. You should think about things like randomness, how the data is represented, and making sure that all sets accurately reflect the overall data.

### Problem Statement

Universal bank is a young bank growing rapidly in terms of overall customer acquisition. The majority of these customers are liability customers (depositors) with varying sizes of relationship with the bank. The customer base of asset customers (borrowers) is quite small, and the bank is interested in expanding this base rapidly in more loan business. In particular, it wants to explore ways of converting its liability customers to personal loan customers. A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise smarter campaigns with better target marketing. The goal is to use k-NN to predict whether a new customer will accept a loan offer. This will serve as the basis for the design of a new campaign. The file UniversalBank.csv contains data on 5000 customers. The data include customer demographic information (age, income, etc.), the customerâ€™s relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.

Partition the data into training (60%) and validation (40%) sets

***

### Data Import and Cleaning

First, load the required libraries

```{r}
library(class)
library(caret)
library(readr)

```
#### Read the data

```{r}
setwd("C:\\Users\\rampa\\OneDrive\\Desktop\\FML_Assignment_2")
universal_data <- read.csv("UniversalBank.csv")
head(universal_data)

```
#### Transpose

```{r}
t(t(names(universal_data)))   #The t function creates a transpose of the dataframe
```

#### Remove ID and ZIP Code as they are not predictors
```{r}
library(dplyr)

universal_data<- select(universal_data, -ID, -ZIP.Code)
summary(universal_data)
```

#### Split Data into 60% training and 40% validation. There are many ways to do this. We will look at 2 different ways. Before we split, let us transform categorical variables into dummy variables

#### Only Education needs to be converted to factor

```{r}
universal_data$Education <- as.factor(universal_data$Education)
head(universal_data$Education)
```
#### Now, convert Education to Dummy Variables

```{r}
dummy_groups <- dummyVars(~., data = universal_data)
universal_data <- as.data.frame(predict(dummy_groups, universal_data))
```

#### Partition data into training (60%) and validation (40%) sets

```{r}
set.seed(1)
train_indices <- sample(row.names(universal_data), 0.6 * nrow(universal_data))
valid_indices <- setdiff(row.names(universal_data), train_indices)

train_df <- universal_data[train_indices, ]
head(train_df)
valid_df <- universal_data[valid_indices, ]
tail(valid_df)
```

#### Normalize the data

```{r}
norm_values <- preProcess(train_df[, -which(names(train_df) %in% c("Personal.Loan"))], method = c("center", "scale"))
train_norm <- predict(norm_values, train_df[, -which(names(train_df) %in% c("Personal.Loan"))])
valid_norm <- predict(norm_values, valid_df[, -which(names(valid_df) %in% c("Personal.Loan"))])
norm_values
head(train_norm)
tail(valid_norm)
```

### Questions

Consider the following customer:

Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1, and Credit Card = 1. Perform a k-NN classification with all predictors except ID and ZIP code using k = 1. Remember to transform categorical predictors with more than two categories into dummy variables first. Specify the success class as 1 (loan acceptance), and use the default cutoff value of 0.5. How would this customer be classified?

#### We have converted all categorical variables to dummy variables
#### Let's create a new sample
```{r}
new_customer <- data.frame(
  Age = 40,
  Experience = 10,
  Income = 84,
  Family = 2,
  CCAvg = 2,
  Education.1 = 0,
  Education.2 = 1,
  Education.3 = 0,
  Mortgage = 0,
  Securities.Account = 0,
  CD.Account = 0,
  Online = 1,
  CreditCard = 1
)

```

#### Normalize the new customer data using the same preprocessing
```{r}
train.norm.df <- train_df[,-10] # Note that Personal Income is the 10th variable
valid.norm.df <- valid_df[,-10]

norm.values <- preProcess(train_df[, -10], method=c("center", "scale"))
train.norm.df <- predict(norm.values, train_df[, -10])
valid.norm.df <- predict(norm.values, valid_df[, -10])
norm.values
head(train.norm.df)
head(valid.norm.df)
```

#### Perform k-NN classification with k=1 for the new customer
```{r}
knn_pred_new_customer <- knn(train = train_norm, test = new_customer, cl = train_df$Personal.Loan, k = 1)
knn_pred_new_customer
```

#### what is a choice of k that balances between overfitting and ignoring the predictor information?

```{r}
accuracy <- rep(0, 15)
for (i in 1:15) {
  knn_pred <- knn(train = train_norm, test = valid_norm, cl = train_df$Personal.Loan, k = i)
  accuracy[i] <- confusionMatrix(knn_pred, as.factor(valid_df$Personal.Loan), positive = "1")$overall[1]
}
best_k <- which.max(accuracy)
```


#### Show the confusion matrix for the validation data that results from using the best k.

```{r}
knn_pred_valid_best_k <- knn(train = train_norm, test = valid_norm, cl = train_df$Personal.Loan, k = best_k)
conf_matrix_valid <- confusionMatrix(knn_pred_valid_best_k, as.factor(valid_df$Personal.Loan), positive = "1")

```


#### Repartition the data into training, validation, and test sets (50% : 30% : 20%)


```{r}
train_indices <- sample(1:nrow(universal_data), 0.5 * nrow(universal_data))
valid_test_indices <- setdiff(1:nrow(universal_data), train_indices)
valid_indices <- sample(valid_test_indices, 0.3 * length(valid_test_indices))
test_indices <- setdiff(valid_test_indices, valid_indices)
train_df <- universal_data[train_indices, ]
valid_df <- universal_data[valid_indices, ]
test_df <- universal_data[test_indices, ]

```


#### Normalize the data for each set

```{r}
norm_values <- preProcess(train_df[, -10], method = c("center", "scale"))
train_norm <- predict(norm_values, train_df[, -10])
valid_norm <- predict(norm_values, valid_df[, -10])
test_norm <- predict(norm_values, test_df[, -10])

```


#### Perform k-NN classification with the best k for the test set

```{r}
knn_pred_test_best_k <- knn(train = train_norm, test = test_norm, cl = train_df$Personal.Loan, k = best_k)

knn_pred_test_best_k

```

#### Create confusion matrices for each set
```{r}
conf_matrix_train <- confusionMatrix(knn(train = train_norm, test = train_norm, cl = train_df$Personal.Loan, k = best_k), as.factor(train_df$Personal.Loan), positive = "1")
conf_matrix_valid <- confusionMatrix(knn(train = train_norm, test = valid_norm, cl = train_df$Personal.Loan, k = best_k), as.factor(valid_df$Personal.Loan), positive = "1")
conf_matrix_test <- confusionMatrix(knn_pred_test_best_k, as.factor(test_df$Personal.Loan), positive = "1")

```


#### Display the confusion matrices
```{r}
conf_matrix_train
conf_matrix_valid
conf_matrix_test
```
 
